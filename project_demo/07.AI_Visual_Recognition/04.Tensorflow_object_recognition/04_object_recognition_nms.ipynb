{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@Copyright (C): 2015-2024, Shenzhen Yahboom Tech\n",
    "@Author: clhchan \n",
    "@Date: 2024-08-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非极大值抑制应用(帧率有所降低)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入oled屏幕库 Import oled screen library\n",
    "import sys\n",
    "sys.path.append('/home/pi/software/oled_yahboom/')\n",
    "from yahboom_oled import *\n",
    "# 创建oled对象 Create an oled object\n",
    "oled = Yahboom_OLED(debug=False)\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os,time\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_utils\n",
    "import ipywidgets.widgets as widgets\n",
    "from image_fun import bgr8_to_jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init camera \n",
    "cap = cv2.VideoCapture(0)  # 定义摄像头对象，参数0表示第一个摄像头 Define the camera object, parameter 0 represents the first camera\n",
    "cap.set(3, 320) # set Width\n",
    "cap.set(4, 240) # set Height\n",
    "cap.set(5, 30)  #设置帧率 Setting the frame rate\n",
    "# cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))\n",
    "# cap.set(cv2.CAP_PROP_BRIGHTNESS, 60) #设置亮度 -64 - 64  0.0 Set Brightness -64 - 64 0.0\n",
    "# cap.set(cv2.CAP_PROP_CONTRAST, 50) #设置对比度 -64 - 64  2.0 Set Contrast -64 - 64 2.0\n",
    "# cap.set(cv2.CAP_PROP_EXPOSURE, 156)  #设置曝光值 1.0 - 5000  156.0 Set the exposure value 1.0 - 5000 156.0\n",
    "\n",
    "# from picamera2 import Picamera2, Preview\n",
    "# import libcamera\n",
    "# picam2 = Picamera2()  \n",
    "# camera_config = picam2.create_preview_configuration(main={\"format\":'RGB888',\"size\":(320,240)})\n",
    "# camera_config[\"transform\"] = libcamera.Transform(hflip=1, vflip=1)\n",
    "# picam2.configure(camera_config) \n",
    "# picam2.start() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpg', width=640, height=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init tf model\n",
    "\n",
    "MODEL_NAME = 'ssdlite_mobilenet_v2_coco_2018_05_09' #fast\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb' \n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt') \n",
    "NUM_CLASSES = 90 \n",
    "IMAGE_SIZE = (12, 8) \n",
    "fileAlreadyExists = os.path.isfile(PATH_TO_CKPT) \n",
    "\n",
    "if not fileAlreadyExists:\n",
    "    print('Model does not exsist !')\n",
    "    exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD GRAPH\n",
    "print('Loading...')\n",
    "detection_graph = tf.Graph() \n",
    "with detection_graph.as_default(): \n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid: \n",
    "        serialized_graph = fid.read() \n",
    "        od_graph_def.ParseFromString(serialized_graph) \n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True) \n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print('Finish Load Graph..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(category_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dict['Name']: \", category_index[1]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Main\n",
    "oled.init_oled_process() #初始化oled进程 Initialize oled process\n",
    "oled.add_line(\"OBJTYPE:\", 1)\n",
    "oled.add_line(\"None\", 3)\n",
    "oled.refresh()\n",
    "t_start = time.time()\n",
    "fps = 0\n",
    "display(image_widget)\n",
    "with detection_graph.as_default():\n",
    "    with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "        while True:\n",
    "            #frame = picam2.capture_array()\n",
    "            ret, frame = cap.read()\n",
    "#            frame = cv2.flip(frame, -1) # Flip camera vertically\n",
    "#             frame = cv2.resize(frame,(320,240))\n",
    "            ##############\n",
    "            image_np_expanded = np.expand_dims(frame, axis=0) \n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0') \n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0') \n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0') \n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0') \n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "#             print('Running detection..') \n",
    "            (boxes, scores, classes, num) = sess.run( \n",
    "                [detection_boxes, detection_scores, detection_classes, num_detections], \n",
    "                feed_dict={image_tensor: image_np_expanded}) \n",
    "\n",
    "#             print('Done.  Visualizing..')\n",
    "            # 应用非极大值抑制\n",
    "            selected_indices = tf.image.non_max_suppression(\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(scores),\n",
    "                max_output_size=100,  # 根据需要设置最大输出数量\n",
    "                iou_threshold=0.7)  # 调整重叠阈值\n",
    "                \n",
    "            # 使用 tf.gather 来高效地应用索引\n",
    "            filtered_boxes = tf.gather(tf.squeeze(boxes), selected_indices)\n",
    "            filtered_scores = tf.gather(tf.squeeze(scores), selected_indices)\n",
    "            filtered_classes = tf.gather(tf.cast(tf.squeeze(classes), tf.int32), selected_indices)\n",
    "            \n",
    "            # 在会话中运行过滤操作\n",
    "            (filtered_boxes, filtered_scores, filtered_classes) = sess.run([\n",
    "                filtered_boxes,\n",
    "                filtered_scores,\n",
    "                filtered_classes\n",
    "            ])\n",
    "            \n",
    "            # 可视化\n",
    "            vis_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                frame,\n",
    "                filtered_boxes,\n",
    "                filtered_classes,\n",
    "                filtered_scores,\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=8)\n",
    "            \n",
    "            for i in range(0, 10):\n",
    "                if scores[0][i] >= 0.7:\n",
    "                    print(category_index[int(classes[0][i])]['name'])\n",
    "                    oled.clear()\n",
    "                    objtype_str=category_index[int(classes[0][i])]['name']\n",
    "                    oled.add_line(\"OBJTYPE:\", 1)\n",
    "                    oled.add_line(objtype_str, 3)\n",
    "                    oled.refresh()\n",
    "            ##############\n",
    "            fps = fps + 1\n",
    "            mfps = fps / (time.time() - t_start)\n",
    "            cv2.putText(frame, \"FPS:\" + str(int(mfps)), (10,25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "            image_widget.value = bgr8_to_jpeg(frame)\n",
    "\n",
    "            k = cv2.waitKey(1) & 0xff\n",
    "            if k == 27:# press 'ESC' to quit\n",
    "                cap.release()\n",
    "                # 恢复屏幕基础数据显示 Restore basic data display on screen\n",
    "                os.system(\"python3 /home/pi/software/oled_yahboom/yahboom_oled.py &\")\n",
    "                break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "# 恢复屏幕基础数据显示 Restore basic data display on screen\n",
    "os.system(\"python3 /home/pi/software/oled_yahboom/yahboom_oled.py &\")\n",
    "# picam2.stop()\n",
    "# picam2.close()\n",
    "#最后需要释放掉摄像头的占用 Finally, you need to release the camera's occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
